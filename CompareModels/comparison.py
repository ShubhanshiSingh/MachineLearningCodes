# -*- coding: utf-8 -*-
"""Comparison.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bQA4LuFgAd7RjIsrzAmAF1labMhzWW8j
"""

#Import Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier  
from sklearn.tree import DecisionTreeClassifier

#Loading of dataset
data_df = pd.read_csv('/content/Iris.csv')
data_df.head()

data_df.drop(['Id'], axis=1, inplace= True)
data_df.head()

data_df.info()

data_df.columns

X = data_df.iloc[:,:-1].values
y = data_df.Species

#Coorelation_matrix
corr_var = data_df.corr()
plt.figure(figsize=(4,3))
sns.heatmap(corr_var, annot=True, cmap = "BuPu")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

classifier2 = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')
classifier2.fit(X_train, y_train)
y_pred = classifier2.predict(X_test)
print("prediction value:", y_pred)

cm = metrics.confusion_matrix(y_test, y_pred)
#visualization of confusion matrix
clas_nam = [0,1]
fig, ax = plt.subplots()
tick_mrks = np.arange(len(clas_nam))
plt.xticks(tick_mrks, clas_nam)
plt.yticks(tick_mrks, clas_nam)

#Heatmap
sns.heatmap(pd.DataFrame(cm), annot=True, cmap="YlGnBu", fmt = 'g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix', y = 1.1)
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')

print(metrics.classification_report(y_test, y_pred))

# Naive Bayes

classifier = GaussianNB()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

# Summary of the predictions made by the classifier
print(metrics.classification_report(y_test, y_pred))

print(metrics.confusion_matrix(y_test, y_pred))

# Accuracy score

print('accuracy is',metrics.accuracy_score(y_pred,y_test))

# K-Nearest Neighbours

classifier = KNeighborsClassifier(n_neighbors=3)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

# Summary of the predictions made by the classifier
print(metrics.classification_report(y_test, y_pred))
print(metrics.confusion_matrix(y_test, y_pred))

# Accuracy score
print('accuracy is',metrics.accuracy_score(y_pred,y_test))

# Decision Tree's

classifier = DecisionTreeClassifier()

classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

# Summary of the predictions made by the classifier
print(metrics.classification_report(y_test, y_pred))
print(metrics.confusion_matrix(y_test, y_pred))

# Accuracy score
print('accuracy is',metrics.accuracy_score(y_pred,y_test))

classifiers = [
    LogisticRegression(),
    GaussianNB(),
    KNeighborsClassifier(),
    DecisionTreeClassifier()
]


log_cols=["Classifier", "Accuracy", "Log Loss"]
log = pd.DataFrame(columns=log_cols)
 
for clf in classifiers:
    clf.fit(X_train, y_train)
    name = clf.__class__.__name__
    
    print("="*30)
    print(name)
    
    print('****Results****')
    train_predictions = clf.predict(X_test)
    acc = metrics.accuracy_score(y_test, train_predictions)
    print("Accuracy: {:.4%}".format(acc))
    
    log_entry = pd.DataFrame([[name, acc*100, 11]], columns=log_cols)
    log = log.append(log_entry)
    
    print("="*30)


sns.set_color_codes("muted")
sns.barplot(x='Accuracy', y='Classifier', data=log, color="b")

plt.xlabel('Accuracy %')
plt.title('Classifier Accuracy')
plt.show()